{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas, NumPy and SciKit Learn modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import precision_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nfl data (games between 2009 to 2019)\n",
    "nfl_df = pd.read_excel('data/nfl_data_2019_season_thru_week17.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1183 entries, 0 to 1182\n",
      "Columns: 1023 entries, game_date to pg4_str_diff_2\n",
      "dtypes: datetime64[ns](5), float64(720), int64(288), object(10)\n",
      "memory usage: 9.2+ MB\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nfl_df.info())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      game_date opp team       week  year\n",
      "5869 2020-01-12  KC  HOU   Division  2019\n",
      "5870 2020-01-12  GB  SEA   Division  2019\n",
      "5871 2020-01-19  KC  TEN  ConfChamp  2019\n",
      "5872 2020-01-19  SF   GB  ConfChamp  2019\n",
      "5873 2020-02-02  KC   SF  SuperBowl  2019\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5874 entries, 0 to 5873\n",
      "Data columns (total 5 columns):\n",
      "game_date    5874 non-null datetime64[ns]\n",
      "opp          5874 non-null object\n",
      "team         5874 non-null object\n",
      "week         5874 non-null object\n",
      "year         5874 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 229.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# add game schedule\n",
    "schedule_df = pd.read_excel('data/schedule.xlsx')\n",
    "print(schedule_df.tail())\n",
    "df = (pd.merge(nfl_df, schedule_df[['game_date', 'team', 'opp', 'year', 'week']], \n",
    "                   left_on = ['game_date', 'team', 'opp'],\n",
    "                    right_on = ['game_date', 'team', 'opp']))\n",
    "print()\n",
    "print(schedule_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     game_date team  opp  home_game  team_score  opp_score  complete_pass  \\\n",
      "17  2019-12-22  ATL  JAX          1          24         12             32   \n",
      "636 2019-12-22  IND  CAR          1          38          6             14   \n",
      "934 2019-12-22  PHI  DAL          1          17          9             31   \n",
      "699 2019-12-22   KC  CHI          0          26          3             23   \n",
      "698 2019-12-22   KC  CHI          0          26          3             23   \n",
      "454 2019-12-22  DET  DEN          0          17         27             12   \n",
      "455 2019-12-22  DET  DEN          0          17         27             12   \n",
      "18  2019-12-22  ATL  JAX          1          24         12             32   \n",
      "533 2019-12-23   GB  MIN          0          23         10             26   \n",
      "534 2019-12-23   GB  MIN          0          23         10             26   \n",
      "\n",
      "     pass_attempt  interception  sack  ...  pg4_avg_opp_fumble_lost_1  \\\n",
      "17             45             2     1  ...                          1   \n",
      "636            27             0     3  ...                          1   \n",
      "934            40             0     1  ...                          0   \n",
      "699            33             0     1  ...                          0   \n",
      "698            33             0     1  ...                          0   \n",
      "454            24             0     4  ...                          2   \n",
      "455            24             0     4  ...                          2   \n",
      "18             45             2     1  ...                          1   \n",
      "533            40             1     3  ...                          0   \n",
      "534            40             1     3  ...                          0   \n",
      "\n",
      "     pg4_avg_yards_gained_1  pg4_avg_opp_yards_gained_1  \\\n",
      "17                      348                         278   \n",
      "636                     391                         315   \n",
      "934                     386                         335   \n",
      "699                     259                         448   \n",
      "698                     259                         448   \n",
      "454                     364                         354   \n",
      "455                     364                         354   \n",
      "18                      348                         278   \n",
      "533                     322                         362   \n",
      "534                     322                         362   \n",
      "\n",
      "     pg4_avg_point_spread_diff_1  pg4_avg_opp_point_spread_diff_1  \\\n",
      "17                          -1.0                            -18.5   \n",
      "636                        -13.0                             14.0   \n",
      "934                        -16.5                            -11.5   \n",
      "699                         20.0                             -9.5   \n",
      "698                         20.0                             -9.5   \n",
      "454                          1.5                             -4.0   \n",
      "455                          1.5                             -4.0   \n",
      "18                          -1.0                            -18.5   \n",
      "533                         11.5                             18.5   \n",
      "534                         11.5                             18.5   \n",
      "\n",
      "     pg4_opp_str_2  pg4_team_str_2  pg4_str_diff_2  year  week  \n",
      "17             -16             -16               0  2019    16  \n",
      "636             34             -28             -62  2019    16  \n",
      "934            -36             -12              24  2019    16  \n",
      "699            -12              62              74  2019    16  \n",
      "698            -12              62              74  2019    16  \n",
      "454            -14              -8               6  2019    16  \n",
      "455            -14              -8               6  2019    16  \n",
      "18             -16             -16               0  2019    16  \n",
      "533             16              36              20  2019    16  \n",
      "534             16              36              20  2019    16  \n",
      "\n",
      "[10 rows x 1025 columns]\n"
     ]
    }
   ],
   "source": [
    "# check out the dataset\n",
    "print(df.sort_values('game_date', ascending = True).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.6667\n",
      "adjusted precision 0.6557\n"
     ]
    }
   ],
   "source": [
    "# custom scoring function\n",
    "# set factor equal to one for precision and increase to further penalize false positives\n",
    "# False positives are bad for nfl survivor\n",
    "prec_plus_factor = 1.05\n",
    "def calc_precision(y, y_hat):\n",
    "    true_positives = ((y == True) & (y_hat == True)).sum()\n",
    "    false_positives = ((y == False) & (y_hat == True)).sum()\n",
    "    if math.isnan(float(true_positives)) or math.isnan(float(false_positives)):\n",
    "        return np.nan\n",
    "    return float(true_positives) / (true_positives + false_positives)\n",
    "\n",
    "def calc_adjusted_precision(y, y_hat):\n",
    "    true_positives = ((y == True) & (y_hat == True)).sum()\n",
    "    false_positives = ((y == False) & (y_hat == True)).sum()\n",
    "    if math.isnan(float(true_positives)) or math.isnan(float(false_positives)):\n",
    "        return np.nan\n",
    "    return float(true_positives) / (true_positives + false_positives * prec_plus_factor)\n",
    "\n",
    "y = np.array([0, 1, 1, 1, 0])\n",
    "x = np.array([0, 0, 1, 1, 1])\n",
    "print('precision {:.4f}'.format(calc_precision(y, x)))\n",
    "print('adjusted precision {:.4f}'.format(calc_adjusted_precision(y, x)))\n",
    "\n",
    "\n",
    "\n",
    "def calc_adjusted_precision_est(est, X, y):\n",
    "    y_hat = est.predict(X).reshape(y.shape)\n",
    "    true_positives = ((y == True) & (y_hat == True)).sum()\n",
    "    false_positives = ((y == False) & (y_hat == True)).sum()\n",
    "    return 1. / (float(true_positives) / (true_positives + false_positives * prec_plus_factor))\n",
    "\n",
    "\n",
    "precision_plus_scorer = make_scorer(calc_adjusted_precision, greater_is_better = True, needs_proba = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up hyperparameters and features \n",
    "\n",
    "# number of games to lookback (moving averages)\n",
    "games_lookback = 6\n",
    "\n",
    "# features\n",
    "# 'is_favorite',\n",
    "x_columns = ['home_game', 'NFC', 'North', 'South', 'West', 'rank_diff', 'directed_spread', \n",
    "             'adj_str_diff_{}'.format(games_lookback), 'str_diff_{}'.format(games_lookback),\n",
    "             'adj_avg_str_diff_{}'.format(games_lookback), 'avg_str_diff_{}'.format(games_lookback),\n",
    "            'team_wins_{}'.format(games_lookback), 'opp_wins_{}'.format(games_lookback), \n",
    "             #'completion_percentage', 'interception_percentage', 'yards_gained',\n",
    "             'avg_completion_percentage_{}'.format(games_lookback), \n",
    "             'avg_interception_percentage_{}'.format(games_lookback),\n",
    "             'avg_yards_gained_{}'.format(games_lookback),\n",
    "             'team_opp_wins_{}'.format(games_lookback)]\n",
    "  \n",
    "y_columns = ['win']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1183 entries, 0 to 1182\n",
      "Data columns (total 3 columns):\n",
      "game_date    1183 non-null datetime64[ns]\n",
      "year         1183 non-null int64\n",
      "week         1183 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(2)\n",
      "memory usage: 37.0 KB\n",
      "None\n",
      "\n",
      "Current week and year: 14 and 2019\n",
      "Upcoming week and year: 15 and 2019\n",
      "split_date: 2019-12-09\n",
      "val_split_date: 2019-12-16\n"
     ]
    }
   ],
   "source": [
    "#start_week = df[df['game_date'] == df['game_date'].min()][['week']].iloc[0].astype(int).values[0]\n",
    "current_year = 2019\n",
    "current_week = 14\n",
    "upcoming_year = current_year + 1 * (current_week == 17)\n",
    "df['week'] = pd.to_numeric(df['week'], errors = 'coerce')\n",
    "upcoming_week = (current_week + 1) * (current_week < 17) + 1 * (current_week == 17)\n",
    "split_date = df[(df['week'] == current_week) & (df['year'] == current_year)]['game_date'].max()\n",
    "val_split_date = df[(df['week'] == upcoming_week) & (df['year'] == upcoming_year)]['game_date'].max()\n",
    "print(df[['game_date', 'year', 'week']].info())\n",
    "print()\n",
    "#print(split_date)\n",
    "#print(start_week)\n",
    "print('Current week and year: {} and {}'.format(current_week, current_year))\n",
    "print('Upcoming week and year: {} and {}'.format(upcoming_week, upcoming_year))\n",
    "print('split_date: {:%Y-%m-%d}'.format(split_date))\n",
    "print('val_split_date: {:%Y-%m-%d}'.format(val_split_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1135 entries, 0 to 1182\n",
      "Columns: 1025 entries, game_date to week\n",
      "dtypes: datetime64[ns](5), float64(720), int64(290), object(10)\n",
      "memory usage: 8.9+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24 entries, 19 to 1158\n",
      "Columns: 1025 entries, game_date to week\n",
      "dtypes: datetime64[ns](5), float64(720), int64(290), object(10)\n",
      "memory usage: 192.4+ KB\n",
      "None\n",
      "     game_date team  opp\n",
      "19  2019-12-15  ATL   SF\n",
      "20  2019-12-15  ATL   SF\n",
      "144 2019-12-15  BUF  PIT\n",
      "145 2019-12-15  BUF  PIT\n",
      "456 2019-12-15  DET   TB\n"
     ]
    }
   ],
   "source": [
    "train_dataset = df[df['game_date'] <= split_date]\n",
    "test_dataset = df[(df['year'] == upcoming_year) & (df['week'] == upcoming_week)]\n",
    "print(train_dataset.info())\n",
    "print()\n",
    "print(test_dataset.info())\n",
    "print(test_dataset[['game_date', 'team', 'opp']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features: 13\n",
      "1021 training samples cases | 114 test samples\n",
      "Dummy ROCAUC is 0.5000\n",
      "RF best score is : 1.5657\n",
      "RF best parameters: {'max_depth': 4, 'max_features': 10, 'n_estimators': 75}\n",
      "\n",
      "max pr: 0.8819\n",
      "RF Train ROCAUC 0.8261 and RF Test ROCAUC 0.6937\n",
      "\n",
      "precision\n",
      "(1021,)\n",
      "Train Precision: 0.730250\n",
      "\n",
      "Validation Precision: 0.698113\n",
      "Adjusted Validation Precision: 0.687732\n",
      "\n",
      "                         Features  Importances\n",
      "2                 directed_spread     0.520731\n",
      "3                  adj_str_diff_6     0.086549\n",
      "5              adj_avg_str_diff_6     0.069603\n",
      "9     avg_completion_percentage_6     0.057819\n",
      "6                  avg_str_diff_6     0.057595\n",
      "11             avg_yards_gained_6     0.050465\n",
      "1                       rank_diff     0.041198\n",
      "4                      str_diff_6     0.041012\n",
      "10  avg_interception_percentage_6     0.039662\n",
      "0                       home_game     0.017816\n",
      "12                team_opp_wins_6     0.007382\n",
      "7                     team_wins_6     0.006051\n",
      "8                      opp_wins_6     0.004117\n",
      "\n",
      "     team  opp  directed_spread  is_favorite  vegas_spread  win  point_diff\n",
      "1178  WAS  DAL             -3.5            0          -3.5    1           7\n",
      "1179  WAS  PHI              3.5            1          -3.5    1          25\n",
      "1180  WAS  OAK              2.0            1          -2.0    1          21\n",
      "1181  WAS   NO             -9.0            0          -9.0    0          -2\n",
      "1182  WAS  PHI            -10.0            0         -10.0    0          -3\n"
     ]
    }
   ],
   "source": [
    "x_cols = [item for item in x_columns if item in train_dataset.columns]\n",
    "X_train, X_val, y_train, y_val = (train_test_split(train_dataset[x_cols], train_dataset[y_columns], \n",
    "                                                     test_size = 0.1,\n",
    "                                                    random_state = 0))\n",
    "\n",
    "print('# of features: {}'.format(X_train.shape[1]))\n",
    "print('{} training samples cases | {} test samples'.format(X_train.shape[0], X_val.shape[0]))\n",
    "dc = DummyClassifier(random_state = 0).fit(X_train, y_train.values.ravel())\n",
    "pr = dc.predict_proba(X_train)\n",
    "fpr, tpr, _ = roc_curve(y_train, pr[:, 1].reshape(len(pr)))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Dummy ROCAUC is {:.4f}'.format(roc_auc))\n",
    "\n",
    "# fine tune random forest parameters\n",
    "grid_values = {'max_features': [5, 10], 'max_depth': [4, 5], 'n_estimators': [50, 75]}\n",
    "rf = RandomForestClassifier(random_state = 0)\n",
    "grid = (GridSearchCV(rf, param_grid = grid_values, \\\n",
    "                    scoring = calc_adjusted_precision_est, cv = 4).fit(X_train, y_train.values.ravel()))\n",
    "print('RF best score is : {:.4f}'.format(grid.best_score_))\n",
    "print('RF best parameters: {}\\n'.format(grid.best_params_))\n",
    "\n",
    "rf = (RandomForestClassifier(random_state = 0, max_features = grid.best_params_['max_features'], \n",
    "                             max_depth = grid.best_params_['max_depth'], \n",
    "                             n_estimators = grid.best_params_['n_estimators'])\n",
    "      .fit(X_train, y_train.values.ravel()))\n",
    "pr = rf.predict_proba(X_train)\n",
    "fpr, tpr, _ = roc_curve(y_train, pr[:, 1].reshape(len(pr)))\n",
    "train_roc_auc = auc(fpr, tpr)\n",
    "pr = rf.predict_proba(X_val)\n",
    "print('max pr: {:.4f}'.format(np.max(pr[:, 1])))\n",
    "fpr, tpr, _ = roc_curve(y_val, pr[:, 1].reshape(len(pr)))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('RF Train ROCAUC {:.4f} and RF Test ROCAUC {:.4f}'.format(train_roc_auc, roc_auc))\n",
    "importance_df = pd.DataFrame({'Features': X_train.columns, 'Importances': rf.feature_importances_}, \n",
    "                             columns = ['Features', 'Importances'], index = range(len(X_train.columns)))\n",
    "\n",
    "print()\n",
    "\n",
    "print('precision')\n",
    "print(rf.predict(X_train).shape)\n",
    "precision = calc_precision(y_train, rf.predict(X_train).reshape(y_train.shape))\n",
    "print('Train Precision: {:4f}'.format(precision['win']))\n",
    "print()\n",
    "precision = calc_precision(y_val, rf.predict(X_val).reshape(y_val.shape))\n",
    "print('Validation Precision: {:4f}'.format(precision['win']))\n",
    "precision = calc_adjusted_precision(y_val, rf.predict(X_val).reshape(y_val.shape))\n",
    "print('Adjusted Validation Precision: {:4f}'.format(precision['win']))\n",
    "\n",
    "print()\n",
    "\n",
    "print(importance_df.sort_values('Importances', ascending = False).head(20)[['Features', 'Importances']])\n",
    "print()\n",
    "print(nfl_df[['team', 'opp', 'directed_spread', 'is_favorite', 'vegas_spread', 'win', 'point_diff']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.666667\n"
     ]
    }
   ],
   "source": [
    "# Check precision on test set\n",
    "precision = (calc_precision(test_dataset[y_columns], rf.predict(test_dataset[x_cols]).\n",
    "                                 reshape(test_dataset[y_columns].shape)))\n",
    "print('Test Precision: {:4f}'.format(precision['win']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
